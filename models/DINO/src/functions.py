import math
import torch
import torch.nn as nn
from typing import List, Tuple, Dict
import timm

def trunc_normal_(tensor, mean=0., std=1., a=-2., b=2.):
    # type: (torch.Tensor, float, float, float, float) -> torch.Tensor
    return fills_val_trunc_normal_(tensor, mean, std, a, b)

def fills_val_trunc_normal_(
    tensor: torch.Tensor, 
    mean: float = 0., 
    std: float = 1., 
    a: float = -2, 
    b: float = 2
) -> torch.Tensor:
    """Fills the input torch.Tensor with values drawn from a truncated normal distribution. If values fall over [2, -2], they are drawn again until within that range.

    Args:
        tensor (torch.Tensor): Input tensor
        mean (float, optional): mean of the normal distribution. Defaults to 0..
        std (float, optional): standard deviation of the normal distribution. Defaults to 1..
        a (float, optional): the minimum cutoff value. Defaults to -2.
        b (float, optional): the maximum cutoff value. Defaults to 2.
    """

    def normal_cdf(x: float):
        # The erf() function can be used to compute traditional statistical functions such as the cumulative standard normal distribution
        return (1. + math.erf(x / math.sqrt(2.)))/2.
    
    if (mean < a - 2*std) or (mean > b + 2*std):
        print("mean is more than 2 std from [a, b]. The distribution of values may be incorrect.")

    # used in inference
    with torch.no_grad():

        # Values are generated by using a truncated uniform distribution and the using the inverse CDF for the normal distribution
        low = normal_cdf((a-mean)/std)
        upper = normal_cdf((b-mean)/std)

        # Uniformely fill tensor with values from [low, upper], then translate to [2*low-1, 2*upper-1]
        tensor.uniform_(2*low-1, 2*upper-1)

        # Use inverse cdf transform for normal distribution to get truncated standard normal
        tensor.erfinv_()

        # Transform tensor to proper mean, std
        tensor.mul_(std * math.sqrt(2.))
        tensor.add_(mean)

        # Clamp to ensure tensor is in the proper range
        tensor.clamp_(min=a, max=b)
        
        return tensor
    
def clip_gradients(model, clip):
    norms = []
    for name, p in model.named_parameters():
        if p.grad is not None:
            param_norm = p.grad.data.norm(2)
            norms.append(param_norm.item())
            clip_coef = clip / (param_norm + 1e-6)
            if clip_coef < 1:
                p.grad.data.mul_(clip_coef)
    return norms

def cancel_gradients_last_layer(epoch, model, frozen_epochs):
    if epoch >= frozen_epochs:
        return
    for n, p in model.named_parameters():
        if "last_layer" in n:
            p.grad = None


def get_out_features(
    model_name: str
) -> int:
    """returns the out features dim of a

    Args:
        model_name (str): model name for timm

    Returns:
        int: model out features dim
    """
    if model_name.startswith("custom_"):
        model_info = model_name.split("_")
        if model_info[2] == "tiny": return 192
        if model_info[2] == "small": return 384
        if model_info[2] == "base": return 768
    else:
        model = timm.create_model(
            model_name=model_name, 
            pretrained=False
        )
        layers = list(model.children())
        return layers[-1].in_features

def load_state_dict_ssl(
    model: nn.Module, 
    ssl_state_dict: Dict, 
    initials: str = "model.student.backbone."
) -> nn.Module:
    """loads weights from self-supervised model into model based on initials params (e.g. "model.student.backbone." are the layers to consider for TeacherStudentSSL models)

    Args:
        model (nn.Module): model
        ssl_state_dict (Dict): self supervised model state dict
        initials (str, optional): layers' initial to consider for loading weights to model. Defaults to "model.student.backbone.".

    Returns:
        nn.Module: model with loaded weights
    """
    count = 0
    for k, v in ssl_state_dict.items():
        if k.startswith(initials):
            _k = k.replace(initials, "")
            if _k in model.state_dict().keys():
                model.state_dict()[_k].copy_(v)
                count += 1
    print(f"> Loaded weights into model for {count}/{len(list(model.state_dict().keys()))} layers.")
    if count == 0:
        print("[WARNING] Unable to load weights properly.")
    return model